{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Task: Find similar company names\n",
    "\n",
    "Now that we have completed our Python Primer, let's try to complete a real task, while at the same time trying to practice loops, iterations, and other Python functionality that we studied.\n",
    "\n",
    "### Your high level task\n",
    "\n",
    "You are given a list of names. You know that the same entity in the list has different representations. You want to find duplicate companies in the data.\n",
    "\n",
    "As a concrete example, open the file under `restaurant-names.txt`. This contains a list of restaurant names, extracted from the [NYC Restaurant inspection data set](https://data.cityofnewyork.us/Health/DOHMH-New-York-City-Restaurant-Inspection-Results/xx67-kt59/data) (available online). The Department of Health has been doing a decent, but not perfect, job in recording the company names. Therefore, the same restaurant appears under different names. **Your task is to find \"almost duplicate\" entries in order to decide whether they correspond to the same business.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matching Company Names\n",
    "\n",
    "Quite often, in our data, we have entries represented as strings that refer to the same entity but have different string representations (e.g., McDonald's vs McDonalds vs McDonald‎). We want to write code that will help in the task of finding such similar entries in our data.\n",
    "\n",
    "Our task can be broken in the following tasks:\n",
    "* **Step 1**: Read the data from a file into a list of strings in memory. We have two data sets under the `data` folder: The list of unique restaurant names from the NYC Restaurant Inspection dataset (`data/restaurant-names.txt`). We need to write Python code that will read these files and return a list of strings that are the company names.\n",
    "* **Step 2**: We will then need to figure out how to compare two strings and find their similarity. For that, we will write a function that takes as input **two** strings, and returns back their similarities. We will explore multiple ways of writing that function, using various library functions.\n",
    "* **Step 3**: We will need to write a function that takes as input a company name, and returns back a list of matching company names, together with their similarity. Ideally, we would like to also sort the list based on the similarity (highest similarity metrics on top). As part of our learning process, we will use the _list comprehension_ approach to create the list. We will also use tuples as the elements of the list, so that the list contain elements such as `[(\"McDonalds\", 0.88), (\"McDonald's\", 0.81),....]`.\n",
    "* **Step 4**: In the final step, we will just perform the similarity computation across all companies in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1: Read the list of names from a file and create a list of names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 1: Read the list of names from a file and create a list of names\n",
    "filename = 'restaurant-names.txt'\n",
    "\n",
    "f = open(filename, 'r')\n",
    "content = f.read()\n",
    "f.close()\n",
    "# Print the first 200 characters of the file\n",
    "print(\"original file ====>\\n\")\n",
    "print(content[0:199])\n",
    "# split the file by line, create a set (i.e.eliminate duplicates)\n",
    "# and sort the set \n",
    "names = sorted(set(content.split('\\n')))\n",
    "print(\"sorted names[0-50] =====>\\n\")\n",
    "\n",
    "print(names[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2: Implement the similarity function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the similarity between two strings\n",
    "\n",
    "There are many ways that we can calculate the similarity between two strings. For our case, we will focus on a few similarity metrics that already have implementations in Python. \n",
    "\n",
    "##### Some commonly used similarity metrics\n",
    "\n",
    "* [Sequence matching](https://docs.python.org/3.6/library/difflib.html) (part of standard Python) ([example](http://stackoverflow.com/questions/17388213/find-the-similarity-percent-between-two-strings))\n",
    "* [Edit distance](https://en.wikipedia.org/wiki/Edit_distance) ([Python Jellyfish Library](https://github.com/jamesturk/jellyfish))\n",
    "* [N-gram distance](http://pythonhosted.org/ngram/tutorial.html#comparing-and-searching-strings)\n",
    "\n",
    "\n",
    "##### STEP 2.a: Let's figure out how we can install the lo we dont have to write codibraries... \n",
    "##### Python has thousands of libraries that we can use so we dont have to write code.\n",
    "##### The jellyfish library has a number text functions that we will find useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edit distance\n",
    "\n",
    "!pip3 install -U jellyfish\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ngram is another libary that will save us from writing code\n",
    "###### An ngram is several words concatenated together to make a N word phrase.\n",
    "###### for instance bigrams of some test would be every 2 word phrase.\n",
    "###### for-instance, instance-bigrams, bigrams-of, ...\n",
    "###### They are very useful in comparisons of texts, as we will see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ngram library\n",
    "!pip3 install -U ngram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 2.b: Now let's test our similarity functions with various examples\n",
    "\n",
    "Once we have installed the necessary libraries for our project, we proceed to `import` them and test the functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jellyfish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Edit Distance\n",
    "\n",
    "From Wikipedia:\n",
    "\n",
    "The [edit distance](https://en.wikipedia.org/wiki/Edit_distance) _ is a way of quantifying how dissimilar two strings (e.g., words) are to one another by counting the minimum number of operations required to transform one string into the other._. \n",
    "\n",
    "The Levenshtein distance between \"kitten\" and \"sitting\" is 3. A minimal edit script that transforms the former into the latter is:\n",
    "\n",
    "* kitten → sitten (substitution of \"s\" for \"k\")\n",
    "* sitten → sittin (substitution of \"i\" for \"e\")\n",
    "* sittin → sitting (insertion of \"g\" at the end)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jellyfish.levenshtein_distance('kitten', 'sitting')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try a few more examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jellyfish.levenshtein_distance('Starbucks', 'Starbacks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jellyfish.levenshtein_distance('Starbucks', 'Starbuck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jellyfish.levenshtein_distance('Starbucks', 'Wendys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Demerau Levenshtein distance\n",
    "\n",
    "The Demerau Levenshtein distance also allows for  transposition of two adjacent characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jellyfish.damerau_levenshtein_distance('Starbucks', 'Starbucsk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jellyfish.levenshtein_distance('Starbucks', 'Starbucsk')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Jaro–Winkler distance\n",
    "\n",
    "[Jaro–Winkler distance](https://en.wikipedia.org/wiki/Jaro%E2%80%93Winkler_distance) is a string metric for measuring the edit distance between two sequences. Informally, the **Jaro** distance between two words is the minimum number of single-character transpositions required to change one word into the other; the **Jaro–Winkler** distance  gives more favourable ratings to strings that match from the beginning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install jaro-winkler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jaro\n",
    "#help(jaro)\n",
    "jaro.jaro_winkler_metric('Starbucks', 'Starbarbr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jaro.jaro_winkler_metric('Starbucks', 'Milwbucks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Soundex\n",
    "\n",
    "[Soundex](https://en.wikipedia.org/wiki/Soundex) is a phonetic algorithm for indexing names by sound, as pronounced in English. The goal is for homophones to be encoded to the same representation so that they can be matched despite minor differences in spelling. \n",
    "\n",
    "Using this algorithm, both \"Robert\" and \"Rupert\" return the same string \"R163\" while \"Rubin\" yields \"R150\". \"Ashcraft\" and \"Ashcroft\" both yield \"A261\". \"Tymczak\" yields \"T522\" not \"T520\" (the chars 'z' and 'k' in the name are coded as 2 twice since a vowel lies in between them). \"Pfister\" yields \"P236\" not \"P123\" (the first two letters have the same number and are coded once as 'P')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jellyfish.soundex('Robert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jellyfish.soundex('Rupert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jellyfish.soundex('Ashcroft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jellyfish.soundex('Ashcraft')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ngrams\n",
    "\n",
    "With the n-gram similarity score, we split the word into sequences of n consecutive characters (n-grams) and then compare the sets of n-grams between the two words. For example, the name \"Panos\" has the following 2-grams: \"Pa\", \"an\", \"no\", \"os\". (We can also add \"#P\" and \"s#\" if we want to capture the prefix and suffixes.) Strings that share a large number of q-grams are often similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram.NGram.compare('Ipeirotis','Iperotis',N=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram.NGram.compare('New York University','New York Universty',N=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 1: Create a function that takes as input two strings and returns their similarity\n",
    "\n",
    "Given the experience with the metrics above, we want now to create a function that takes as input a string and returns their similarity. Our key requirement is for the similarity metric to be between 0 and 1, with 0 meaning no similarity, and 1 corresponding to identical strings. Some of the similarity functions above would fit right in, others will need some work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For n-gram similarity it is very simple, we just return the result\n",
    "def computeSimilarity(str1, str2):\n",
    "    return ngram.NGram.compare(str1,str2,N=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeSimilarity('New York University','New York')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For edit distance, we need to normalize. \n",
    "# Edit distance is always the maximum of the length of the two strings\n",
    "# (can you figure out why?) so we can use that to normalize the distance\n",
    "def computeSimilarity(str1, str2):\n",
    "    dist = jellyfish.levenshtein_distance(str1, str2)\n",
    "    max_dist = max(len(str1), len(str2))\n",
    "    similarity = 1 - dist/max_dist\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "computeSimilarity('New York University','New York')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Task 2: Modify the functions above to allow for various similarity calculation methods.\n",
    "\n",
    "We will now up our game, and return back the results of the comparison using multiple methods at once. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeSimilarity_2gram(str1, str2):\n",
    "    return ngram.NGram.compare(str1,str2,N=2)\n",
    "\n",
    "def computeSimilarity_3gram(str1, str2):\n",
    "    return ngram.NGram.compare(str1,str2,N=3)\n",
    "\n",
    "def computeSimilarity_edit_distance(str1, str2):\n",
    "    dist = jellyfish.levenshtein_distance(str1, str2)\n",
    "    max_dist = max(len(str1), len(str2))\n",
    "    similarity = 1 - dist/max_dist\n",
    "    return similarity\n",
    "\n",
    "def computeSimilarity_soundex(str1, str2):\n",
    "    s1 = jellyfish.soundex(str1)\n",
    "    s2 = jellyfish.soundex(str2)\n",
    "    if (s1==s2):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeSimilarity(str1, str2, method):\n",
    "    if method == '2-gram':\n",
    "        return computeSimilarity_2gram(str1, str2)\n",
    "    elif method == '3-gram':\n",
    "        return computeSimilarity_3gram(str1, str2)\n",
    "    elif method == 'levenshtein':\n",
    "        return computeSimilarity_edit_distance(str1, str2)\n",
    "    elif method == 'soundex':\n",
    "        return computeSimilarity_soundex(str1, str2)\n",
    "    \n",
    "computeSimilarity('New York University','New York', method='3-gram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a bit more advanced, conceptually.\n",
    "# Instead of selecting a method to use, we use all available methods to \n",
    "# do our comparison, and we return a dictionary with the results\n",
    "# This approach would be useful when dealing with the problem \n",
    "# as a classification problem (match vs no match) and we want to\n",
    "# use the distance values as features\n",
    "def computeSimilarity_all(str1, str2):\n",
    "    result = {\n",
    "        '2-gram': computeSimilarity_2gram(str1, str2),\n",
    "        '3-gram': computeSimilarity_3gram(str1, str2),\n",
    "        'levenshtein': computeSimilarity_edit_distance(str1, str2),\n",
    "        'soundex': computeSimilarity_soundex(str1, str2)\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "computeSimilarity_all('New York University','New York Universty')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3: Compute similarity of a company against a list of company names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create a function that accepts a company name and a list of companies, and computes their similarity. This part will get us to exercise our for-loops, and also illustrate how we can use lists and tuples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sorting a list of tuples**:_This part is a little bit advanced for now, so I will just give the code below. (Solution taken from http://stackoverflow.com/questions/3121979/how-to-sort-list-tuple-of-lists-tuples). Here is a small example below, which we will reuse in our function:_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(\"Vee\",0.5), (\"Henry\",0.6), (\"Oscar\", 0.4)]\n",
    "data.sort(key=lambda tupl: tupl[1], reverse=True)  # sorts in place, in descending order, based on the second element of the tuple\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 3: We now create a function that accepts a company name\n",
    "# and a list of companies, and computes their similarity\n",
    "# We have a 'top' parameter (by default set to be 5)\n",
    "# that restricts the results to only the most similar \n",
    "# string pairs. We also define a parameter \"method\" that defines \n",
    "# what is the similarity method that we want to use. We also define a \n",
    "# similarity threshold for keeping only results with sufficient similarity\n",
    "\n",
    "def queryData(query, companyList, top = 5, method = '2-gram', sim_threshold = 0.7):\n",
    "    # Initialize the list\n",
    "    results = []\n",
    "    # Go over all the companies in the data set....\n",
    "    for company in companyList:\n",
    "        # Compute the similarity of each company against the \"query\" variable\n",
    "        sim = computeSimilarity(query, company, method)\n",
    "        # We keep only results with sufficient similarity and we do not keep identical names\n",
    "        if sim > sim_threshold and query!=company:\n",
    "            # We store the similar company name, and the value of their similarity\n",
    "            results.append( (company, sim) )\n",
    "    # With the command below we sort the results, and put the most similar results in the top\n",
    "    results.sort(key=lambda tupl: tupl[1], reverse=True)\n",
    "    # We return only the first \"threshold\" results\n",
    "    return results[:top]\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = queryData(\"MCDONALDS\", names)\n",
    "r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Perform the similarity computation across all companies in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4: We are almost done. We now just go through all the companies in the list\n",
    "# and we call the companySimilarity function that computes the similar company names\n",
    "# for all the companies in the list. We store the results in a dictionary, with the \n",
    "# key being the company name, and the value being a \"list of tuples\" with the \n",
    "# similar company names and the corresponding similarity value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for companyName in names:\n",
    "    matches = queryData(companyName, names)\n",
    "    for match, sim in matches:\n",
    "        print(companyName, \"\\t\", match, \"\\t\", sim)\n",
    "        i = i + 1\n",
    "    if i>5000: \n",
    "        break # We stop after 50 matches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
